{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nanochat JAX/Flax Training on TPU\n",
    "\n",
    "This notebook sets up and runs JAX training on Google Colab TPU.\n",
    "\n",
    "**Important:** Before running, go to `Runtime > Change runtime type` and select **TPU** as the hardware accelerator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Verify TPU Runtime\n",
    "\n",
    "First, let's check that we have TPU access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check if TPU is available\n",
    "if 'COLAB_TPU_ADDR' in os.environ:\n",
    "    print(f\"TPU address: {os.environ['COLAB_TPU_ADDR']}\")\n",
    "else:\n",
    "    print(\"WARNING: TPU not detected!\")\n",
    "    print(\"Go to Runtime > Change runtime type > Hardware accelerator > TPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clone the Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/snaidu/nanochat.git\n",
    "%cd nanochat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Install uv Package Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "\n",
    "# Add uv to PATH for this session\n",
    "os.environ['PATH'] = f\"{os.environ['HOME']}/.local/bin:{os.environ['PATH']}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install Python and sync dependencies with TPU support\n!uv python install 3.13\n!uv sync --extra tpu"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install JAX with TPU support\n",
    "!uv pip install jax[tpu] -f https://storage.googleapis.com/jax-releases/libtpu_releases.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv run python -c \"\n",
    "import jax\n",
    "print('JAX version:', jax.__version__)\n",
    "print('Devices:', jax.devices())\n",
    "print('Number of devices:', len(jax.devices()))\n",
    "print('Device type:', jax.devices()[0].platform if jax.devices() else 'None')\n",
    "\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. Prepare Dataset\n\nThis downloads the FineWeb-Edu dataset. For a quick test, we download just 10 shards (~1-2 GB).\n\n**Note:** Full dataset is ~200GB (1823 shards). Use `-n 10` for testing."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Download 10 dataset shards for testing (~1-2 GB)\n# Increase -n for more data, or remove it for the full dataset\n!uv run python -m nanochat.dataset -n 10"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. Train Tokenizer\n\nTrain a BPE tokenizer on the downloaded data."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Train the BPE tokenizer\n!uv run python -m scripts.tok_train"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test JAX Model\n",
    "\n",
    "Quick sanity check that the model works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv run python -c \"\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import nnx\n",
    "from nanochat.jax.gpt import GPT, GPTJaxConfig\n",
    "\n",
    "config = GPTJaxConfig(\n",
    "    sequence_len=128,\n",
    "    vocab_size=50304,\n",
    "    n_layer=4,\n",
    "    n_head=4,\n",
    "    n_kv_head=4,\n",
    "    n_embd=128,\n",
    "    dtype=jnp.bfloat16,\n",
    ")\n",
    "model = GPT(config, rngs=nnx.Rngs(0))\n",
    "print('Model created successfully!')\n",
    "\n",
    "# Test forward pass\n",
    "x = jax.random.randint(jax.random.key(0), (2, 64), 0, 1000)\n",
    "y = jax.random.randint(jax.random.key(1), (2, 64), 0, 1000)\n",
    "loss = model(x, y)\n",
    "print(f'Forward pass works! Loss: {loss}')\n",
    "\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Run Training\n",
    "\n",
    "Now run the actual training script. Adjust parameters as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small test run (adjust parameters for longer training)\n",
    "!uv run python -m scripts.jax.base_train \\\n",
    "    --depth=4 \\\n",
    "    --max-seq-len=512 \\\n",
    "    --device-batch-size=8 \\\n",
    "    --num-iterations=100 \\\n",
    "    --eval-every=50 \\\n",
    "    --warmup-steps=10 \\\n",
    "    --learning-rate=3e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Multi-Device Training (Optional)\n",
    "\n",
    "If you have multiple TPU cores, enable multi-device training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-device training (uses all TPU cores)\n",
    "!uv run python -m scripts.jax.base_train \\\n",
    "    --depth=4 \\\n",
    "    --max-seq-len=512 \\\n",
    "    --device-batch-size=32 \\\n",
    "    --num-iterations=100 \\\n",
    "    --eval-every=50 \\\n",
    "    --multi-device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Larger Model Training\n",
    "\n",
    "Once everything works, try a larger model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Larger model (depth=12, ~85M params)\n",
    "!uv run python -m scripts.jax.base_train \\\n",
    "    --depth=12 \\\n",
    "    --max-seq-len=1024 \\\n",
    "    --device-batch-size=16 \\\n",
    "    --num-iterations=1000 \\\n",
    "    --eval-every=100 \\\n",
    "    --warmup-steps=100 \\\n",
    "    --multi-device"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": [],
   "gpuType": "V28"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}